{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DennisLin/anaconda2/envs/ece143/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import xlrd\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')   \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from matplotlib.colors import rgb2hex\n",
    "from matplotlib.patches import Polygon\n",
    "from pyquery import PyQuery as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_states = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado',\n",
    "                   'Connecticut', 'Delaware', 'Dist. of Col.', \n",
    "                   'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', \n",
    "                   'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', \n",
    "                   'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri',\n",
    "                   'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey',\n",
    "                   'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', \n",
    "                   'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', \n",
    "                   'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah',\n",
    "                   'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin',\n",
    "                   'Wyoming']\n",
    "WC = ('Washington', 'Oregon', 'California', 'Nevada', 'Arizona', 'Alaska', 'Hawaii')\n",
    "RM = ('Montana', 'Idaho', 'Wyoming', 'Utah', 'Colorado')\n",
    "GC = ('New Mexico',  'Texas', 'Arkansas', 'Louisiana',  'Mississippi', 'Alabama')\n",
    "Midwest = ('North Dakota',  'South Dakota', 'Nebraska',  'Kansas', 'Oklahoma', \n",
    "           'Minnesota', 'Iowa', 'Missouri', 'Wisconsin', 'Illinois', 'Indiana', 'Kentucky',\n",
    "           'Michigan',  'Tennessee', 'Ohio')\n",
    "\n",
    "East = ('Florida',  'Georgia', 'South Carolina', 'North Carolina', 'Virginia', 'West Virginia', \n",
    "              'Maryland',  'Delaware',  'Pennsylvania',  'New Jersey',  'New York',  'Connecticut', \n",
    "              'Rhode Island',  'Vermont',  'New Hampshire',  'Massachusetts',  'Maine', 'Dist. of Col.')\n",
    "state_regions = [East, Midwest, GC, RM, WC]\n",
    "Region = [\"East Coast\", \"Midwest\", \"Gulf Coast\", \"Rocky Mountain\", \"West Coast\"]\n",
    "price_url = 'https://www.eia.gov/dnav/pet/hist/LeafHandler.ashx?n=PET&s=EMM_EPM0_PTE_R10_DPG&f=W'\n",
    "import_url = 'https://www.eia.gov/dnav/pet/hist/LeafHandler.ashx?n=PET&s=WTTIM_R10-Z00_2&f=W'\n",
    "stock_url = 'https://www.eia.gov/dnav/pet/hist/LeafHandler.ashx?n=PET&s=WCESTP11&f=W'\n",
    "population_path = './population/nst-est2018-01.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(string):\n",
    "    '''\n",
    "    Change the type from string to list and remove redundant ''\n",
    "    Args:\n",
    "        string: (str) string loaded from pyquery\n",
    "    Return:\n",
    "        data: (list) \n",
    "    '''\n",
    "    assert isinstance(string, str)\n",
    "    string = string.replace(',', '').replace('.', '').replace('NA', '0').split(' ')\n",
    "    \n",
    "    return list(filter(lambda a: a != '', string))\n",
    "    \n",
    "def url2df(url, name):\n",
    "    '''\n",
    "    use pyquery to crawl the data and convert it to pandas.dataframe\n",
    "    Args:\n",
    "        url: (str) website url for crawling\n",
    "        name: (str) the name of the data\n",
    "    Return:\n",
    "        data: (DataFrame) \n",
    "    '''\n",
    "    assert isinstance(url, str)\n",
    "    assert isinstance(name, str)\n",
    "    html_doc = pq(url)\n",
    "    html_doc.contents()\n",
    "    \n",
    "    value = \".B3:nth-child(3)\"\n",
    "    date = \".B6\"\n",
    "    \n",
    "    value_data = preprocess(html_doc(value).text())\n",
    "    value_data = list(map(int, value_data))\n",
    "    date_data = preprocess(html_doc(date).text())    \n",
    "    data = pd.DataFrame(value_data, columns = [name], index = date_data)\n",
    "    return data\n",
    "\n",
    "def url2df_im(url, name):\n",
    "    '''\n",
    "    use pyquery to crawl the data and convert it to pandas.dataframe\n",
    "    Args:\n",
    "        url: (str) website url for crawling\n",
    "        name: (str) the name of the data\n",
    "    Return:\n",
    "        data: (DataFrame) \n",
    "    '''\n",
    "    assert isinstance(url, str)\n",
    "    assert isinstance(name, str)\n",
    "    html_doc = pq(url)\n",
    "    html_doc.contents()\n",
    "    \n",
    "    value = \".B3:nth-child(3)\"\n",
    "    date = \".B6\"\n",
    "    \n",
    "    value_data = preprocess(html_doc(value).text())\n",
    "    value_data = [value_data[0]] + value_data\n",
    "    value_data =  list(map(int, value_data))\n",
    "    date_data = preprocess(html_doc(date).text())    \n",
    "    data = pd.DataFrame(value_data, columns = [name], index = date_data)\n",
    "    return data\n",
    "\n",
    "def url2np(url, name):\n",
    "    '''\n",
    "    use pyquery to crawl the data and convert it to numpy array\n",
    "    Args:\n",
    "        url: (str) website url for crawling\n",
    "        name: (str) the name of the data\n",
    "    Return:\n",
    "        data: (numpy array) \n",
    "    '''\n",
    "    assert isinstance(url, str)\n",
    "    assert isinstance(name, str)\n",
    "    html_doc = pq(url)\n",
    "    html_doc.contents()\n",
    "    \n",
    "    value = \".B3\"\n",
    "    date = \".B5\"\n",
    "    \n",
    "    value_data = preprocess(html_doc(value).text())\n",
    "    value_data = list(map(int, value_data))\n",
    "    date_data = preprocess(html_doc(date).text())    \n",
    "    array = np.array([date_data, value_data])\n",
    "    return array\n",
    "\n",
    "def dict2df(dic):\n",
    "    '''\n",
    "    Transform a dictionary object to dataframe\n",
    "    Args:\n",
    "        dic: (dictionary)\n",
    "    Return: \n",
    "        df: (DataFrame)\n",
    "    '''\n",
    "    assert isinstance(dic, dict)\n",
    "    df = pd.DataFrame()\n",
    "    for name, url in dic.items():\n",
    "        df = pd.concat([df, url2df(url, name)], axis = 1)\n",
    "    return df\n",
    "\n",
    "def dict2df_im(dic):\n",
    "    '''\n",
    "    Transform a dictionary object to dataframe, while dealing with the edge case on `import`\n",
    "    Args: \n",
    "        dic: (dictionary)\n",
    "    Return: \n",
    "        df: (DataFrame)\n",
    "    '''\n",
    "    assert isinstance(dic, dict)\n",
    "    df = pd.DataFrame()\n",
    "    for name, url in dic.items():\n",
    "        df = pd.concat([df, url2df_im(url, name)], axis = 1)\n",
    "    return df\n",
    "\n",
    "def get_correlate(df_price, df_factor):\n",
    "    '''\n",
    "    Retuen the correlation of two df.dataframe\n",
    "    Args:\n",
    "        df_price: (pd.DataFrame)\n",
    "        df_factor: (pd.DataFrame)\n",
    "    Return:\n",
    "        coor: (dict)\n",
    "    '''\n",
    "    assert isinstance(df_price, pd.DataFrame)\n",
    "    assert isinstance(df_factor, pd.DataFrame)\n",
    "    coor = {}\n",
    "    for i, r in enumerate(Region):\n",
    "        price_array = normalized(df_price[[r]].values)\n",
    "        factor_array = normalized(df_factor[[r]].values)        \n",
    "        min_length = min([price_array.shape[0], factor_array.shape[0]])\n",
    "        price_array, factor_array = price_array[-min_length:], factor_array[-min_length:]\n",
    "        coor[r] = np.correlate(price_array.squeeze() , factor_array.squeeze())/min_length\n",
    "    return coor\n",
    "\n",
    "def normalized(numpydata):\n",
    "    '''\n",
    "    Normalized the numpy array.\n",
    "    Args:\n",
    "        numpydata: (nparray)\n",
    "    '''\n",
    "    assert isinstance(numpydata, np.ndarray)\n",
    "    max_ = np.max(numpydata)\n",
    "    min_ = np.min(numpydata)\n",
    "    return (numpydata-min_)/(max_-min_)\n",
    "\n",
    "def name_process(array):\n",
    "    '''\n",
    "    preprocess the naming conflict between two object\n",
    "    '''\n",
    "    assert isinstance(array, np.ndarray)\n",
    "    out = []\n",
    "    for i, region in enumerate(state_regions):\n",
    "        out.append(array.item().get(region))\n",
    "    return out\n",
    "\n",
    "def create_heatmap(coor_dict, cmap, tit):\n",
    "    '''\n",
    "    Create the heapmap of correlation between factors and the fossil prices.\n",
    "    For more color map, please check: https://matplotlib.org/examples/color/colormaps_reference.html\n",
    "    Args:\n",
    "        coor_dict: (dict)\n",
    "        cmap: the colormap type\n",
    "        title: (str) i.e. 'Correlation between price and import in different region'\n",
    "    '''\n",
    "    assert isinstance(coor_dict, dict)\n",
    "    assert isinstance(tit, str)\n",
    "    m = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49,\n",
    "            projection='lcc',lat_1=33,lat_2=45,lon_0=-95)\n",
    "    m.readshapefile('./shape/st99_d00','states',drawbounds=True)\n",
    "    ATOLL_CUTOFF = 0.005\n",
    "    colors={}\n",
    "    statenames=[]\n",
    "    vmin = min(coor_dict.items(), key=lambda x: x[1])[1]\n",
    "    vmax= max(coor_dict.items(), key=lambda x: x[1])[1]\n",
    "    # vmin = 0; vmax = 1\n",
    "    for shapedict in m.states_info:\n",
    "        statename = shapedict['NAME']\n",
    "        if statename not in ['District of Columbia','Puerto Rico']:\n",
    "            value = coor_dict[statename]\n",
    "            colors[statename] = cmap((value-vmin)/(vmax-vmin))[:3]\n",
    "        statenames.append(statename)\n",
    "    ax = plt.gca() # get current axes instance\n",
    "    fig = plt.gcf()\n",
    "    for nshape,seg in enumerate(m.states):\n",
    "        if statenames[nshape] not in ['Puerto Rico', 'District of Columbia']:\n",
    "            color = rgb2hex(colors[statenames[nshape]]) \n",
    "            poly = Polygon(seg,facecolor=color,edgecolor='black')\n",
    "            ax.add_patch(poly)\n",
    "    for i, shapedict in enumerate(m.states_info):\n",
    "    #fill the color for hawaii and Alaska\n",
    "        if shapedict['NAME'] not in ['Puerto Rico', 'District of Columbia']:\n",
    "    # Translate the noncontiguous states:\n",
    "            if shapedict['NAME'] in ['Alaska', 'Hawaii']:\n",
    "                seg = m.states[int(shapedict['SHAPENUM'] - 1)]\n",
    "                # maintain the information of 8 main islands of Hawaii, rescale\n",
    "                if shapedict['NAME'] == 'Hawaii' and float(shapedict['AREA']) > ATOLL_CUTOFF:\n",
    "                    seg = list(map(lambda xy: ((xy[0] + 5500000)*0.8, 0.8*(xy[1]-1200000)), seg))\n",
    "                # Rescale Alaska\n",
    "                elif shapedict['NAME'] == 'Alaska':\n",
    "                    seg = list(map(lambda xy: (0.33*xy[0] + 1100000, 0.33*xy[1]-1300000), seg))\n",
    "        \n",
    "            color = rgb2hex(colors[shapedict['NAME']]) \n",
    "            poly = Polygon(seg, facecolor=color, edgecolor='black', linewidth=0.8)\n",
    "            ax.add_patch(poly)\n",
    "    plt.title(tit)\n",
    "    cax = fig.add_axes([0.27, 0.1, 0.5, 0.05]) # posititon\n",
    "    cb = ColorbarBase(cax,cmap=cmap, orientation='horizontal')\n",
    "    plt.show() \n",
    "\n",
    "def create_corr_map(corr_dict):\n",
    "    '''\n",
    "    create the dictionary suitable for mapping to the US map\n",
    "    Args:\n",
    "        corr_dict: (dictionary) \n",
    "    Return:\n",
    "        corr_map: (dictionary)\n",
    "    '''\n",
    "    assert isinstance(corr_dict, dict)\n",
    "    corr_map = {}\n",
    "    for i, region in enumerate(state_regions):\n",
    "        for state in region:\n",
    "            corr_map[state] = corr_dict[Region[i]][0]\n",
    "    return corr_map\n",
    "\n",
    "def downsample(df, start_year, end_year):\n",
    "    '''\n",
    "    Downsample the pandas.dataframe to the data in some period of years.\n",
    "    Args:\n",
    "        df: (pandas.dataframe)\n",
    "        start_year: (int)\n",
    "        end_year: (int)\n",
    "    Return:\n",
    "        df_price_down: (pandas.dataframe)\n",
    "    '''\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    assert start_year >= df.index.year[0]\n",
    "    assert end_year <= df.index.year[-1]\n",
    "    # df.index = pd.to_datetime(df.index)\n",
    "    df_tmp = df_price.groupby(df.index.year).transform('mean')\n",
    "    df_price_down = df_tmp.iloc[(df_tmp.index.month == 2) & (df_tmp.index.year >= start_year) & (df_tmp.index.year <= end_year)]\n",
    "    return df_price_down\n",
    "\n",
    "def corr_bar(import_cor,vehicle_cor,pop_cor):\n",
    "    '''\n",
    "    plot the bar chart of correlation\n",
    "    Args:\n",
    "        import_cor:(dictionary)\n",
    "        pop_cor:(dictionary)\n",
    "        vehicle:(dictionary)\n",
    "        \n",
    "    '''\n",
    "    assert isinstance(import_cor, dict)\n",
    "    assert isinstance(pop_cor, dict)\n",
    "    assert isinstance(vehicle_cor, dict)\n",
    "    imp_value,vhc_value,pop_value=[],[],[]\n",
    "    region_name,region_name2,region_name3=[],[],[]\n",
    "\n",
    "    # for reg, val in import_cor.items():\n",
    "    for reg in Region:\n",
    "        region_name.append(reg)\n",
    "        imp_value.append(round(import_cor[reg][0],3))\n",
    "        region_name2.append(reg)\n",
    "        vhc_value.append(round(vehicle_cor[reg][0],3))\n",
    "        region_name3.append(reg)\n",
    "        pop_value.append(round(pop_cor[reg][0],3))\n",
    "    assert(region_name==region_name2)\n",
    "    assert(region_name==region_name3)\n",
    "    imp=tuple(imp_value)\n",
    "    vhc=tuple(vhc_value)\n",
    "    pop=tuple(pop_value)\n",
    "    region=tuple(region_name)\n",
    "    \n",
    "    ind = np.arange(len(imp))  # the x locations for the groups\n",
    "    width = 0.2  # the width of the bars\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(ind - width, imp, width, \n",
    "                    color='SkyBlue', label='Imports vs. Gas Price')\n",
    "    rects2 = ax.bar(ind , vhc, width,\n",
    "                    color='IndianRed', label='Vehicles vs. Gas Price')\n",
    "    rects3 = ax.bar(ind + width, pop, width,\n",
    "                    color='Purple', label='Population vs. Gas Price')\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Raw correlation')\n",
    "    ax.set_title('Comparison of Correlations')\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(region)\n",
    "    ax.grid(axis = 'y')\n",
    "    ax.legend()\n",
    "    \n",
    "    \n",
    "    def autolabel(rects, xpos='center'):\n",
    "        \"\"\"\n",
    "        Attach a text label above each bar in *rects*, displaying its height.\n",
    "    \n",
    "        *xpos* indicates which side to place the text w.r.t. the center of\n",
    "        the bar. It can be one of the following {'center', 'right', 'left'}.\n",
    "        \"\"\"\n",
    "    \n",
    "        xpos = xpos.lower()  # normalize the case of the parameter\n",
    "        ha = {'center': 'center', 'right': 'left', 'left': 'right'}\n",
    "        offset = {'center': 0.5, 'right': 0.57, 'left': 0.43} \n",
    "    \n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width()*offset[xpos], 1.01*height,\n",
    "                    '{}'.format(height), ha=ha[xpos], va='bottom')\n",
    "    \n",
    "    \n",
    "    autolabel(rects1, \"center\")\n",
    "    autolabel(rects2, \"center\")\n",
    "    autolabel(rects3, \"center\")\n",
    "    plt.show()\n",
    "\n",
    "def load_vehicle(num_year):  \n",
    "    '''\n",
    "    load the preprocessed vehicle data\n",
    "    '''      \n",
    "    year = []\n",
    "    for year_i in range(num_year):\n",
    "        year.append(str(1997+year_i))\n",
    "        npy_file = \"./vehicle/dic_{}.npy\".format(year_i + 1997)\n",
    "        tmp_array = name_process(np.load(npy_file))\n",
    "        new_vehicle = np.array(tmp_array).reshape([1, -1]) \n",
    "        if year_i == 0:\n",
    "            vehicles = new_vehicle\n",
    "        else:\n",
    "            vehicles = np.vstack((vehicles, new_vehicle))\n",
    "    return pd.DataFrame(vehicles, columns = Region, index = year).div(10**8)\n",
    "\n",
    "def load_population(path):\n",
    "    '''\n",
    "    load the population data\n",
    "    '''\n",
    "    assert isinstance(path, str)\n",
    "    wb = xlrd.open_workbook(path) \n",
    "    sheet = wb.sheet_by_index(0) \n",
    "    population = np.zeros((5, 9))    \n",
    "    left = 9\n",
    "    right = 60\n",
    "    coloumn_total = 15\n",
    "    year = []\n",
    "    for iter_year in range(9):\n",
    "        year.append(str(2010+iter_year))\n",
    "        for iter_table in range(left, right):\n",
    "            for iter_region in range(5):\n",
    "                if All_states[iter_table-left] in state_regions[iter_region]:\n",
    "                    population[iter_region, iter_year] += int(float(sheet.cell_value(iter_table, 3+iter_year)))\n",
    "    return pd.DataFrame(population.T, columns = Region, index = year).div(10**8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gas_price = {}\n",
    "    price_dict, import_dict, stock_dict, export_dict, refine_dict  = {}, {}, {}, {}, {}\n",
    "\n",
    "    #store url\n",
    "    for i, r in enumerate(Region):\n",
    "        price_dict[r] = price_url.replace('10', '%d') %(10*(i+1))\n",
    "        import_dict[r] = import_url.replace('10', '%d') %(10*(i+1))\n",
    "\n",
    "    #load url\n",
    "    df_price = dict2df(price_dict).div(1000)\n",
    "    df_import = dict2df_im(import_dict)\n",
    "\n",
    "    #plot price figure using rolling mean\n",
    "    price_fig = df_price.rolling(12).mean().plot.line(title= 'Retail Gas Price vs. Time')\n",
    "    df_price.index = pd.to_datetime(df_price.index)\n",
    "    start_year = df_price.index[0].year\n",
    "    end_year = df_price.index[-1].year\n",
    "    positions = []\n",
    "    for p in df_price.index:\n",
    "        if p.year == start_year and p.month == 1:\n",
    "            positions.append(str(p.year))\n",
    "        elif p.year == end_year and p.month == 1:\n",
    "            positions.append(str(p.year))            \n",
    "        elif p.month == 1  and p.year % 3 == 0:\n",
    "            positions.append(str(p.year))\n",
    "        else:\n",
    "            positions.append(str(''))\n",
    "    price_fig.set_xticks(range(len(positions)))\n",
    "    price_fig.set_xticklabels(positions)\n",
    "    price_fig.set_xlabel(\"Year\")\n",
    "    price_fig.set_ylabel(\"Gas Price per gallon ($/gal)\")\n",
    "    price_fig.grid(axis = 'y')\n",
    "    plt.show()\n",
    "\n",
    "    #plot import figure using rolling mean\n",
    "    import_fig = df_import.rolling(12).mean().plot.line(title = 'Imports of Crude Oil vs. Time')\n",
    "    df_import.index = pd.to_datetime(df_import.index)\n",
    "    positions = []\n",
    "    for p in df_import.index:\n",
    "        if p.year == start_year and p.month == 1:\n",
    "            positions.append(str(p.year))\n",
    "        elif p.year == end_year and p.month == 1:\n",
    "            positions.append(str(p.year))            \n",
    "        elif p.month == 1  and p.year % 2 == 1:\n",
    "            positions.append(str(p.year))\n",
    "        else:\n",
    "            positions.append(str(''))\n",
    "    import_fig.set_xticks(range(len(positions)))\n",
    "    import_fig.set_xticklabels(positions)\n",
    "    import_fig.set_xlabel(\"Year\")\n",
    "    import_fig.set_ylabel(\"Barrels per day (thousands)\")\n",
    "    import_fig.grid(axis = 'y')\n",
    "    plt.show() \n",
    "    \n",
    "    #derive the correlation \n",
    "    import_cor = get_correlate(df_price, df_import)\n",
    "    print('The correlation of import:', import_cor)\n",
    "    \n",
    "    #build the correlation map\n",
    "    import_corr_map = create_corr_map(import_cor)\n",
    "    title = 'Correlation of \\nImports vs. Gas Price'\n",
    "    create_heatmap(import_corr_map, plt.cm.Oranges, title)\n",
    "\n",
    "    #%%\n",
    "    #load the vehicles data\n",
    "    df_vehicle = load_vehicle(18)\n",
    "\n",
    "    #plot the vehicle figure\n",
    "    ve_fig = df_vehicle.plot.line(title = 'Vehicle Registrations vs. Time', grid = True, lw = 2)\n",
    "    df_vehicle.index = pd.to_datetime(df_vehicle.index)\n",
    "    positions = []\n",
    "    for p in df_vehicle.index:         \n",
    "        if p.month == 1  and p.year % 2 == 0:\n",
    "            positions.append(str(p.year))\n",
    "        else:\n",
    "            positions.append(str(''))\n",
    "    box = ve_fig.get_position()\n",
    "    ve_fig.set_position([box.x0, box.y0, box.width*0.85, box.height])\n",
    "    ve_fig.set_xticks(range(len(positions)))\n",
    "    ve_fig.set_xticklabels(positions)    \n",
    "    ve_fig.set_xlabel(\"Year\")\n",
    "    ve_fig.set_ylabel(\"Vehicles (100 millions)\")    \n",
    "    ve_fig.legend(bbox_to_anchor=(1,1))\n",
    "    plt.show()    \n",
    "    df_price_down = downsample(df_price, int(df_vehicle.index[0].year), int(df_vehicle.index[-1].year))\n",
    "    \n",
    "    #derive the correlation \n",
    "    vehicle_cor = get_correlate(df_price_down, df_vehicle)    \n",
    "    print('The correlation of vehicles:', vehicle_cor)\n",
    "\n",
    "    #build the map\n",
    "    vehicle_corr_map = create_corr_map(vehicle_cor)\n",
    "    title = 'Correlation of \\nVehicle Registrations vs. Gas Price'\n",
    "    create_heatmap(vehicle_corr_map, plt.cm.Greens, title)    \n",
    "    \n",
    "    #%%\n",
    "    #load the populations data    \n",
    "    df_population = load_population(population_path)\n",
    "\n",
    "    #plot the population data\n",
    "    pop_fig = df_population.plot.line(title = 'Population vs. Time', grid = True, lw = 2)\n",
    "    df_population.index = pd.to_datetime(df_population.index)\n",
    "    positions = [p.year for p in df_population.index if p.month == 1]\n",
    "    box = pop_fig.get_position()\n",
    "    pop_fig.set_position([box.x0, box.y0, box.width*0.85, box.height])\n",
    "    pop_fig.set_xticklabels(positions)    \n",
    "    pop_fig.set_xlabel(\"Year\")\n",
    "    pop_fig.set_ylabel(\"Population (100 millions)\")\n",
    "    pop_fig.legend(bbox_to_anchor=(1,1))\n",
    "    plt.show()    \n",
    "    df_price_down = downsample(df_price, int(df_population.index[0].year), int(df_population.index[-1].year))\n",
    "    \n",
    "    #derive the correlation\n",
    "    pop_cor = get_correlate(df_price_down, df_population) \n",
    "    print('Correlation of populations:', pop_cor)\n",
    "    \n",
    "    #build the correlation map\n",
    "    pop_corr_map = create_corr_map(pop_cor)\n",
    "    title = 'Correlation of \\nPopulation vs. Gas Price'\n",
    "    create_heatmap(pop_corr_map, plt.cm.Blues, title)\n",
    "    \n",
    "    #build the bar graph\n",
    "    bar_chart=corr_bar(import_cor,vehicle_cor,pop_cor)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
